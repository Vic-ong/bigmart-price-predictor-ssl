{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Semi-supervised learning (SSL) to predict sales price of a given product\n",
    "### Source: https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/\n",
    "### Data: Test.csv & Train.csv\n",
    "### Problem Statement\n",
    "The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and find out the sales of each product at a particular store.\n",
    "\n",
    "Using this model, BigMart will try to understand the properties of products and stores which play a key role in increasing sales.\n",
    "\n",
    " \n",
    "\n",
    "Please note that the data may have missing values as some stores might not report all the data due to technical glitches. Hence, it will be required to treat them accordingly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data sets from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Test.csv')\n",
    "test = pd.read_csv('./Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select features to be used for data modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fields to keep\n",
    "fields = [\n",
    "    'Item_Weight',\n",
    "    'Item_Fat_Content',\n",
    "    'Outlet_Establishment_Year',\n",
    "    'Outlet_Size',\n",
    "    'Item_Visibility',\n",
    "    'Item_MRP',\n",
    "    'Outlet_Location_Type',\n",
    "    'Outlet_Type',\n",
    "    'Item_Outlet_Sales'\n",
    "]\n",
    "\n",
    "train = train[train.columns.intersection(fields)]\n",
    "test = test[test.columns.intersection(fields)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data\n",
    "- Impute missing weight with mean\n",
    "- Reduce categorical values and encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute mean\n",
    "train['Item_Weight'].fillna((train['Item_Weight'].mean()), inplace=True)\n",
    "test['Item_Weight'].fillna((test['Item_Weight'].mean()), inplace=True)\n",
    "\n",
    "# reduce fat content to two categories\n",
    "train['Item_Fat_Content'] = train['Item_Fat_Content'].replace(\n",
    "    ['low fat', 'LF'], ['Low Fat', 'Low Fat'])\n",
    "train['Item_Fat_Content'] = train['Item_Fat_Content'].replace(['reg'], [\n",
    "                                                              'Regular'])\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace(\n",
    "    ['low fat', 'LF'], ['Low Fat', 'Low Fat'])\n",
    "test['Item_Fat_Content'] = test['Item_Fat_Content'].replace(['reg'], [\n",
    "                                                            'Regular'])\n",
    "\n",
    "# calculate establishment year\n",
    "train['Outlet_Establishment_Year'] = 2013 - train['Outlet_Establishment_Year']\n",
    "test['Outlet_Establishment_Year'] = 2013 - test['Outlet_Establishment_Year']\n",
    "# default small for missing outlet_size\n",
    "train['Outlet_Size'].fillna('Small', inplace=True)\n",
    "test['Outlet_Size'].fillna('Small', inplace=True)\n",
    "\n",
    "# label encoding cate. var.\n",
    "col = ['Outlet_Size', 'Outlet_Location_Type',\n",
    "       'Outlet_Type', 'Item_Fat_Content']\n",
    "test['Item_Outlet_Sales'] = 0\n",
    "\n",
    "combi = train.append(test)\n",
    "number = LabelEncoder()\n",
    "for i in col:\n",
    "    combi[i] = number.fit_transform(combi[i].astype('str'))\n",
    "    combi[i] = combi[i].astype('int')\n",
    "train = combi[:train.shape[0]]\n",
    "test = combi[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into X_train, y_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set features and labels\n",
    "test = test.drop('Item_Outlet_Sales', axis=1)\n",
    "y_train = train['Item_Outlet_Sales']\n",
    "train = train.drop('Item_Outlet_Sales', axis=1)\n",
    "\n",
    "features = train.columns\n",
    "target = 'Item_Outlet_Sales'\n",
    "\n",
    "X_train, X_test = train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get rough estimates by training different regressor algorithms with the labelled data.\n",
    "- Select the algorithm that gives us the best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1bd30396c5b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBayesianRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mElasticNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtraTreesRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import BayesianRidge, Ridge, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
